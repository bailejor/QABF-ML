{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 14 samples\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.6854 - acc: 0.6214 - val_loss: 0.6068 - val_acc: 0.8143\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6286 - acc: 0.7500 - val_loss: 0.5550 - val_acc: 0.8571\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5840 - acc: 0.7786 - val_loss: 0.5144 - val_acc: 0.8714\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5487 - acc: 0.8143 - val_loss: 0.4814 - val_acc: 0.9286\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5197 - acc: 0.8429 - val_loss: 0.4543 - val_acc: 0.9286\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4957 - acc: 0.8571 - val_loss: 0.4315 - val_acc: 0.9286\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4752 - acc: 0.8500 - val_loss: 0.4119 - val_acc: 0.9286\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.8643 - val_loss: 0.3950 - val_acc: 0.9286\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4422 - acc: 0.8643 - val_loss: 0.3803 - val_acc: 0.9286\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4288 - acc: 0.8714 - val_loss: 0.3674 - val_acc: 0.9286\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4169 - acc: 0.8714 - val_loss: 0.3560 - val_acc: 0.9143\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4063 - acc: 0.8714 - val_loss: 0.3457 - val_acc: 0.9143\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3966 - acc: 0.8714 - val_loss: 0.3364 - val_acc: 0.9143\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3879 - acc: 0.8786 - val_loss: 0.3279 - val_acc: 0.9143\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3800 - acc: 0.8786 - val_loss: 0.3202 - val_acc: 0.9143\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3727 - acc: 0.8786 - val_loss: 0.3131 - val_acc: 0.9143\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3660 - acc: 0.8786 - val_loss: 0.3066 - val_acc: 0.9143\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3597 - acc: 0.8786 - val_loss: 0.3005 - val_acc: 0.9143\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3540 - acc: 0.8857 - val_loss: 0.2949 - val_acc: 0.9143\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3486 - acc: 0.8857 - val_loss: 0.2897 - val_acc: 0.9143\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3436 - acc: 0.8857 - val_loss: 0.2849 - val_acc: 0.9286\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3389 - acc: 0.8857 - val_loss: 0.2803 - val_acc: 0.9286\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3345 - acc: 0.8857 - val_loss: 0.2761 - val_acc: 0.9429\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3303 - acc: 0.8857 - val_loss: 0.2721 - val_acc: 0.9429\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3264 - acc: 0.8929 - val_loss: 0.2683 - val_acc: 0.9429\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3227 - acc: 0.8929 - val_loss: 0.2648 - val_acc: 0.9429\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3191 - acc: 0.9000 - val_loss: 0.2614 - val_acc: 0.9429\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3158 - acc: 0.9000 - val_loss: 0.2582 - val_acc: 0.9429\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3125 - acc: 0.9000 - val_loss: 0.2551 - val_acc: 0.9429\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3095 - acc: 0.9071 - val_loss: 0.2522 - val_acc: 0.9429\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3066 - acc: 0.9071 - val_loss: 0.2494 - val_acc: 0.9429\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3037 - acc: 0.9071 - val_loss: 0.2468 - val_acc: 0.9429\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3010 - acc: 0.9071 - val_loss: 0.2443 - val_acc: 0.9571\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2984 - acc: 0.9071 - val_loss: 0.2419 - val_acc: 0.9571\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2959 - acc: 0.9071 - val_loss: 0.2396 - val_acc: 0.9571\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2935 - acc: 0.9071 - val_loss: 0.2374 - val_acc: 0.9571\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2912 - acc: 0.9071 - val_loss: 0.2353 - val_acc: 0.9571\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2890 - acc: 0.9071 - val_loss: 0.2333 - val_acc: 0.9571\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2868 - acc: 0.9071 - val_loss: 0.2314 - val_acc: 0.9571\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2847 - acc: 0.9071 - val_loss: 0.2295 - val_acc: 0.9571\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2827 - acc: 0.9071 - val_loss: 0.2277 - val_acc: 0.9571\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2807 - acc: 0.9000 - val_loss: 0.2260 - val_acc: 0.9571\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2788 - acc: 0.9000 - val_loss: 0.2243 - val_acc: 0.9571\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2770 - acc: 0.9000 - val_loss: 0.2227 - val_acc: 0.9571\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2752 - acc: 0.9071 - val_loss: 0.2212 - val_acc: 0.9571\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2735 - acc: 0.9071 - val_loss: 0.2197 - val_acc: 0.9714\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2718 - acc: 0.9071 - val_loss: 0.2183 - val_acc: 0.9714\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2701 - acc: 0.9071 - val_loss: 0.2169 - val_acc: 0.9714\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2685 - acc: 0.9071 - val_loss: 0.2156 - val_acc: 0.9714\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2670 - acc: 0.9071 - val_loss: 0.2143 - val_acc: 0.9714\n",
      "[[0.06439518 0.06877977 0.85748523 0.04356883 0.08063272]\n",
      " [0.20202562 0.52181    0.4021409  0.13564827 0.16155419]\n",
      " [0.03764347 0.13708313 0.52735126 0.00593283 0.05509907]\n",
      " [0.19824049 0.18398206 0.74755824 0.20993465 0.19764756]\n",
      " [0.18454355 0.18065771 0.7852179  0.15975833 0.15801294]\n",
      " [0.06812893 0.07016328 0.89656067 0.04670838 0.06145972]\n",
      " [0.19239458 0.92993236 0.03963497 0.02037862 0.5030021 ]\n",
      " [0.07121474 0.10539941 0.7998114  0.02487277 0.04169649]\n",
      " [0.05324361 0.16969006 0.60180515 0.01114223 0.06281294]\n",
      " [0.12086254 0.14993906 0.80025095 0.0936425  0.0866576 ]\n",
      " [0.29225302 0.87267584 0.03152605 0.01753026 0.60038096]\n",
      " [0.2771237  0.70713323 0.0452337  0.03639394 0.4745468 ]\n",
      " [0.43135744 0.75397444 0.09389902 0.08310883 0.445563  ]\n",
      " [0.22157933 0.74930185 0.16278517 0.10621233 0.16878311]]\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True False  True  True False]\n",
      " [ True  True  True  True  True]]\n",
      "accuracy of predictions is  0.9285714285714286\n",
      "0.227\n",
      "[[ 1.  1.  5.  3.  2.  1.  2. 13.  9.  4.]\n",
      " [ 0.  3.  2.  1.  0.  0.  9.  6.  2.  0.]\n",
      " [ 5.  5.  5.  5.  4.  8. 12. 15.  8.  6.]\n",
      " [ 0.  0.  3.  3.  0.  0.  0.  7.  8.  0.]\n",
      " [ 0.  0.  3.  1.  0.  0.  0.  9.  2.  0.]\n",
      " [ 0.  0.  5.  1.  1.  0.  0. 15.  3.  3.]\n",
      " [ 1.  5.  0.  1.  5.  2. 15.  0.  2. 15.]\n",
      " [ 2.  2.  5.  1.  1.  6.  6. 15.  1.  1.]\n",
      " [ 5.  5.  5.  2.  5.  6.  9. 14.  2.  5.]\n",
      " [ 0.  1.  4.  0.  0.  0.  2. 12.  0.  0.]\n",
      " [ 4.  4.  1.  1.  5.  9. 12.  1.  2. 15.]\n",
      " [ 3.  4.  0.  5.  4.  9. 12.  0. 12.  9.]\n",
      " [ 4.  3.  0.  1.  2.  6.  9.  0.  3.  6.]\n",
      " [ 0.  5.  1.  2.  0.  0. 14.  2.  6.  0.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc4e8bfb9f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeaveOneOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m'''for leave one out cross fold validation'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from math import sqrt\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataframe = pandas.read_csv(\"/Users/Bailejor/Desktop/QABF-NN/RealdataIntensity.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X_train = dataset[:,0:10].astype(float)\n",
    "y_train = dataset[:,10:15].astype(float)\n",
    "\n",
    "\n",
    "#dataframe = pandas.read_csv(\"Realtest.csv\", header=None)\n",
    "#dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "#X_test = dataset[:,0:5].astype(float)\n",
    "#y_test = dataset[:,5:10]\n",
    "\n",
    "\n",
    "#split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state = seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5000, activation='relu', input_dim=X_train.shape[1]))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=2000)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "print(preds)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "#score = compare preds and y_test\n",
    "print(preds)\n",
    "print(y_test)\n",
    "c = (np.array(preds) == np.array(y_test))\n",
    "added = 0\n",
    "print(c)\n",
    "for i in c:\n",
    "\tif False in i:\n",
    "\t\tadded = added + 1\n",
    "print(\"accuracy of predictions is \", (len(y_test)-added)/len(y_test))\n",
    "\n",
    "interval = 1.77 * sqrt( (0.64 * (1 - 0.64)) / 14)\n",
    "print('%.3f' % interval)\n",
    "print(X_test)\n",
    "\n",
    "kfold = LeaveOneOut()   \n",
    "'''for leave one out cross fold validation'''\n",
    "results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
    "\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 14 samples\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.6854 - acc: 0.6214 - val_loss: 0.6068 - val_acc: 0.8143\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6286 - acc: 0.7500 - val_loss: 0.5550 - val_acc: 0.8571\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5840 - acc: 0.7786 - val_loss: 0.5144 - val_acc: 0.8714\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5487 - acc: 0.8143 - val_loss: 0.4814 - val_acc: 0.9286\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5197 - acc: 0.8429 - val_loss: 0.4543 - val_acc: 0.9286\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4957 - acc: 0.8571 - val_loss: 0.4315 - val_acc: 0.9286\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4752 - acc: 0.8500 - val_loss: 0.4119 - val_acc: 0.9286\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.8643 - val_loss: 0.3950 - val_acc: 0.9286\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4422 - acc: 0.8643 - val_loss: 0.3803 - val_acc: 0.9286\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4288 - acc: 0.8714 - val_loss: 0.3674 - val_acc: 0.9286\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4169 - acc: 0.8714 - val_loss: 0.3560 - val_acc: 0.9143\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4063 - acc: 0.8714 - val_loss: 0.3457 - val_acc: 0.9143\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3966 - acc: 0.8714 - val_loss: 0.3364 - val_acc: 0.9143\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3879 - acc: 0.8786 - val_loss: 0.3280 - val_acc: 0.9143\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3800 - acc: 0.8786 - val_loss: 0.3202 - val_acc: 0.9143\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3727 - acc: 0.8786 - val_loss: 0.3131 - val_acc: 0.9143\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3660 - acc: 0.8786 - val_loss: 0.3066 - val_acc: 0.9143\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3597 - acc: 0.8786 - val_loss: 0.3005 - val_acc: 0.9143\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3540 - acc: 0.8857 - val_loss: 0.2949 - val_acc: 0.9143\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3486 - acc: 0.8857 - val_loss: 0.2897 - val_acc: 0.9143\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3436 - acc: 0.8857 - val_loss: 0.2849 - val_acc: 0.9286\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3389 - acc: 0.8857 - val_loss: 0.2803 - val_acc: 0.9286\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3345 - acc: 0.8857 - val_loss: 0.2761 - val_acc: 0.9429\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3303 - acc: 0.8857 - val_loss: 0.2721 - val_acc: 0.9429\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3264 - acc: 0.8929 - val_loss: 0.2683 - val_acc: 0.9429\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3227 - acc: 0.8929 - val_loss: 0.2648 - val_acc: 0.9429\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3191 - acc: 0.9000 - val_loss: 0.2614 - val_acc: 0.9429\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3158 - acc: 0.9000 - val_loss: 0.2582 - val_acc: 0.9429\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3126 - acc: 0.9000 - val_loss: 0.2551 - val_acc: 0.9429\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3095 - acc: 0.9071 - val_loss: 0.2522 - val_acc: 0.9429\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3066 - acc: 0.9071 - val_loss: 0.2494 - val_acc: 0.9429\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3037 - acc: 0.9071 - val_loss: 0.2468 - val_acc: 0.9429\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3010 - acc: 0.9071 - val_loss: 0.2443 - val_acc: 0.9571\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2984 - acc: 0.9071 - val_loss: 0.2419 - val_acc: 0.9571\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2959 - acc: 0.9071 - val_loss: 0.2396 - val_acc: 0.9571\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2935 - acc: 0.9071 - val_loss: 0.2374 - val_acc: 0.9571\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2912 - acc: 0.9071 - val_loss: 0.2353 - val_acc: 0.9571\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2890 - acc: 0.9071 - val_loss: 0.2333 - val_acc: 0.9571\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2868 - acc: 0.9071 - val_loss: 0.2314 - val_acc: 0.9571\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2847 - acc: 0.9071 - val_loss: 0.2295 - val_acc: 0.9571\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2827 - acc: 0.9071 - val_loss: 0.2277 - val_acc: 0.9571\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2807 - acc: 0.9000 - val_loss: 0.2260 - val_acc: 0.9571\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2788 - acc: 0.9000 - val_loss: 0.2243 - val_acc: 0.9571\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2770 - acc: 0.9000 - val_loss: 0.2227 - val_acc: 0.9571\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2752 - acc: 0.9071 - val_loss: 0.2212 - val_acc: 0.9571\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2735 - acc: 0.9071 - val_loss: 0.2197 - val_acc: 0.9714\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2718 - acc: 0.9071 - val_loss: 0.2183 - val_acc: 0.9714\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2701 - acc: 0.9071 - val_loss: 0.2169 - val_acc: 0.9714\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2686 - acc: 0.9071 - val_loss: 0.2156 - val_acc: 0.9714\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2670 - acc: 0.9071 - val_loss: 0.2143 - val_acc: 0.9714\n",
      "[[0.06439964 0.06878049 0.8574832  0.04356728 0.08064435]\n",
      " [0.20203178 0.5217941  0.4021649  0.13566257 0.16155836]\n",
      " [0.03764883 0.13707165 0.52735037 0.00593415 0.05510988]\n",
      " [0.19824573 0.18399087 0.7475485  0.20993547 0.1976621 ]\n",
      " [0.18454713 0.18066464 0.7852129  0.15976086 0.1580273 ]\n",
      " [0.06813177 0.07016597 0.89655596 0.04670865 0.06147062]\n",
      " [0.19240975 0.92992973 0.03963409 0.02038532 0.50302714]\n",
      " [0.07122018 0.10539963 0.7998214  0.02487277 0.04170594]\n",
      " [0.05324758 0.16966197 0.6018287  0.0111433  0.06281826]\n",
      " [0.12086589 0.14993855 0.80024683 0.09364501 0.08666842]\n",
      " [0.29226288 0.8726723  0.03152576 0.01753472 0.6004232 ]\n",
      " [0.27714503 0.70713294 0.04523245 0.03640483 0.47455838]\n",
      " [0.43136707 0.7539749  0.09390089 0.0831219  0.44559067]\n",
      " [0.22159413 0.7492619  0.16280484 0.10621867 0.16878498]]\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True False  True  True False]\n",
      " [ True  True  True  True  True]]\n",
      "accuracy of predictions is  0.9285714285714286\n",
      "0.227\n",
      "[[ 1.  1.  5.  3.  2.  1.  2. 13.  9.  4.]\n",
      " [ 0.  3.  2.  1.  0.  0.  9.  6.  2.  0.]\n",
      " [ 5.  5.  5.  5.  4.  8. 12. 15.  8.  6.]\n",
      " [ 0.  0.  3.  3.  0.  0.  0.  7.  8.  0.]\n",
      " [ 0.  0.  3.  1.  0.  0.  0.  9.  2.  0.]\n",
      " [ 0.  0.  5.  1.  1.  0.  0. 15.  3.  3.]\n",
      " [ 1.  5.  0.  1.  5.  2. 15.  0.  2. 15.]\n",
      " [ 2.  2.  5.  1.  1.  6.  6. 15.  1.  1.]\n",
      " [ 5.  5.  5.  2.  5.  6.  9. 14.  2.  5.]\n",
      " [ 0.  1.  4.  0.  0.  0.  2. 12.  0.  0.]\n",
      " [ 4.  4.  1.  1.  5.  9. 12.  1.  2. 15.]\n",
      " [ 3.  4.  0.  5.  4.  9. 12.  0. 12.  9.]\n",
      " [ 4.  3.  0.  1.  2.  6.  9.  0.  3.  6.]\n",
      " [ 0.  5.  1.  2.  0.  0. 14.  2.  6.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from math import sqrt\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataframe = pandas.read_csv(\"/Users/Bailejor/Desktop/QABF-NN/RealdataIntensity.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X_train = dataset[:,0:10].astype(float)\n",
    "y_train = dataset[:,10:15].astype(float)\n",
    "\n",
    "\n",
    "#dataframe = pandas.read_csv(\"Realtest.csv\", header=None)\n",
    "#dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "#X_test = dataset[:,0:5].astype(float)\n",
    "#y_test = dataset[:,5:10]\n",
    "\n",
    "\n",
    "#split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state = seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5000, activation='relu', input_dim=X_train.shape[1]))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=2000)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "print(preds)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "#score = compare preds and y_test\n",
    "print(preds)\n",
    "print(y_test)\n",
    "c = (np.array(preds) == np.array(y_test))\n",
    "added = 0\n",
    "print(c)\n",
    "for i in c:\n",
    "\tif False in i:\n",
    "\t\tadded = added + 1\n",
    "print(\"accuracy of predictions is \", (len(y_test)-added)/len(y_test))\n",
    "\n",
    "interval = 1.77 * sqrt( (0.64 * (1 - 0.64)) / 14)\n",
    "print('%.3f' % interval)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
